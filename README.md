# ğŸ’¡ LLM-Powered TDS Companion

A lightweight, intelligent assistant for exploring and understanding content from the **Tools in Data Science** (TDS) course, powered by LLMs. This project crawls and parses course pages and discussions from IITM's Discourse forums, converts them into semantic Markdown chunks, generates vector embeddings, and allows intelligent querying and interaction.

---

## ğŸš€ Features

- ğŸŒ **Web Crawler**: Uses Playwright to extract content from the TDS course site.
- ğŸ§  **Semantic Chunking**: Splits content into meaningful segments using `semantic-text-splitter`.
- ğŸ–¼ï¸ **Image Understanding**: Optionally uses Gemini or OpenAI models to describe attached images.
- ğŸ—‚ï¸ **Vector Embedding**: Embeds chunks using Nomic or OpenAI for downstream semantic search.
- ğŸ” **Search & Retrieval**: Enables RAG-style interaction for answering course-related questions.
- âš™ï¸ **Prompt Testing with Promptfoo**: Compatible with prompt-based evaluation using `promptfoo`.
- ğŸ”„ **CI/CD via GitHub Actions**: Auto-syncs with Hugging Face Spaces upon each push.

---

## ğŸ“ Project Structure

â”œâ”€â”€ tds_pages_md/ # Crawled markdown pages from the official TDS course site
â”œâ”€â”€ discourse_md/ # Markdown files generated from forum discussions
â”œâ”€â”€ scripts/ # Scripts to crawl, convert, embed, and serve
â”œâ”€â”€ app.py # Entry point for web-based or CLI interaction
â”œâ”€â”€ course_content.npz # Precomputed embeddings and chunks (optional)
â”œâ”€â”€ metadata.json # Metadata about crawled pages
â”œâ”€â”€ README.md # This file
â””â”€â”€ .github/workflows/ # GitHub Actions for syncing to Hugging Face

yaml
Copy
Edit

---

## âš™ï¸ Setup Instructions

### ğŸ”§ Requirements

- Python 3.9+
- `poetry` or `pip`
- Hugging Face account
- (Optional) OpenAI or Google Gemini API keys

### ğŸ Install dependencies

```bash
pip install -r requirements.txt
Or use poetry install if using poetry.

ğŸŒ Crawl and Process Content
bash
Copy
Edit
python crawl_tds.py                # Crawl course website
python discourse_to_md.py         # Convert Discourse JSON to Markdown
python embed_chunks.py            # Generate and cache embeddings
ğŸ§ª Test with Promptfoo
To test your app with shared prompt evaluations:

bash
Copy
Edit
# Start your local server or interface
python app.py

# Then test via hosted promptfoo evaluation:
# Replace with your endpoint and token if needed
Promptfoo is optional, but helps improve prompt reliability and behavior testing.

ğŸ”„ Syncing with Hugging Face
This project uses GitHub Actions to automatically deploy to Hugging Face Spaces. On every push to main, the codebase is synced.

ğŸŒ Hosted App
ğŸ‘‰ Try it on Hugging Face Spaces

ğŸ§  Models Used
You can configure the backend to use any of the following for embeddings or vision:

[OpenAI (text-embedding-3-small, gpt-4o)]

[Gemini 2.5 (via Google Generative AI API)]

[Nomic Embeddings for cost-effective open-source options]

ğŸ’¬ Example Use Cases
â€œWhat is the main idea behind Week 3?â€

â€œSummarize the key discussion in the deployment tools thread.â€

â€œWhat does this image in the course material describe?â€

ğŸ™Œ Contributing
Contributions are welcome! Feel free to open issues, feature requests, or pull requests.

ğŸ“œ License
This project is licensed under the MIT License.

âœ¨ Acknowledgements
IITM Online Degree Team

Hugging Face for Spaces

OpenAI / Google for API support

Community TAs for forum discussions